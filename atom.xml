<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Bin Han</title>
  <subtitle>Statistics, AI and Machine Learning</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-01-09T03:23:57.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Fast Gradient Boosting Machine from Microsoft</title>
    <link href="http://yoursite.com/2017/01/lightGBM/"/>
    <id>http://yoursite.com/2017/01/lightGBM/</id>
    <published>2017-01-07T16:05:18.000Z</published>
    <updated>2017-01-09T03:23:57.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Microsoft-LightGBM"><a href="#Microsoft-LightGBM" class="headerlink" title="Microsoft LightGBM"></a>Microsoft LightGBM</h1><p>People in ML community should be familiar with <a href="http://xgboost.readthedocs.io/en/latest/" target="_blank" rel="external">XGBoost</a>, which is a fast implementation of Gradient Boosting Tree Model. Yet recently Microsoft <a href="https://www.dmtk.io/" target="_blank" rel="external">DMTK</a> team open-sourced its own implementation of GBM named <a href="https://github.com/Microsoft/LightGBM" target="_blank" rel="external">LightGBM</a>, claiming to be even faster than XGBoost and consume much less memory (see the <a href="https://github.com/Microsoft/LightGBM/wiki/Experiments#comparison-experiment" target="_blank" rel="external">experiments</a> ). It has accumulated &gt;2000 stars and &gt;400 forks on GitHub in just a few months.</p>
<h1 id="What’s-Nice-about-it"><a href="#What’s-Nice-about-it" class="headerlink" title="What’s Nice about it"></a>What’s Nice about it</h1><p>The fundamental improvement on algorithms is constructing histograms on continuous features, instead of pre-sorting feature values. In GBM setting the precision loss is almost negligible b/c each tree can be regarded as a weak learner. There are other interesting features as well:</p>
<ul>
<li>no need to construct dummy columns for categorical features (avoid one-hot encoding)</li>
<li>leaf-wise tree growth with an option to control tree depth</li>
<li>use histogram subtraction to derive child node based on parent node and sibling node</li>
<li>sparse feature optimization</li>
<li>supports parallel computing through MPI/OpenMP, and also optimized the algorithms in parallel learning</li>
<li>can deploy/load model with light weight .json file</li>
<li>can continue to train on previous saved model with changed setting and specs</li>
</ul>
<p>Please check more detailed explanations <a href="https://github.com/Microsoft/LightGBM/wiki/Features" target="_blank" rel="external">here</a>.</p>
<h1 id="Installation-on-Mac"><a href="#Installation-on-Mac" class="headerlink" title="Installation (on Mac)"></a>Installation (on Mac)</h1><p>The <a href="https://github.com/Microsoft/LightGBM/wiki/Installation-Guide" target="_blank" rel="external">installation guide</a> is very straightforward, but might subject to slight tweak for various OS. The important thing is that LightGBM is built on version 6.* of gcc/g++ so make sure you have the right version installed.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">brew update</div><div class="line">brew install cmake</div><div class="line">brew reinstall gcc --without-multilib</div><div class="line">git clone --recursive https://github.com/Microsoft/LightGBM ; cd LightGBM</div><div class="line">mkdir build ; cd build</div><div class="line">cmake -DCMAKE_CXX_COMPILER=g++-6 -DCMAKE_C_COMPILER=gcc-6 .. </div><div class="line">make -j</div></pre></td></tr></table></figure>
<p>To install the Python API you need to do the following</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd LightGBM/python-package</div><div class="line">python setup.py install</div></pre></td></tr></table></figure>
<h1 id="Python-API"><a href="#Python-API" class="headerlink" title="Python API"></a>Python API</h1><p>I found the API very clean and easy-to-use. For example, to initialize the data:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</div><div class="line"></div><div class="line">lgb_train = lgb.Dataset(X_train, y_train,</div><div class="line">                        weight=W_train, free_raw_data=<span class="keyword">False</span>)</div><div class="line">lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train,</div><div class="line">                       weight=W_test, free_raw_data=<span class="keyword">False</span>)</div></pre></td></tr></table></figure>
<p>To specify model parameters and train the model:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">params = &#123;</div><div class="line">    <span class="string">'boosting_type'</span>: <span class="string">'gbdt'</span>,</div><div class="line">    <span class="string">'objective'</span>: <span class="string">'binary'</span>,</div><div class="line">    <span class="string">'metric'</span>: <span class="string">'binary_logloss'</span>,</div><div class="line">    <span class="string">'num_leaves'</span>: <span class="number">31</span>,</div><div class="line">    <span class="string">'learning_rate'</span>: <span class="number">0.05</span>,</div><div class="line">    <span class="string">'feature_fraction'</span>: <span class="number">0.9</span>,</div><div class="line">    <span class="string">'bagging_fraction'</span>: <span class="number">0.8</span>,</div><div class="line">    <span class="string">'bagging_freq'</span>: <span class="number">5</span>,</div><div class="line">    <span class="string">'verbose'</span>: <span class="number">0</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">gbm = lgb.train(params, lgb_train, num_boost_round=<span class="number">10</span>,</div><div class="line">                valid_sets=lgb_train,  <span class="comment"># eval training data</span></div><div class="line">                categorical_feature=[<span class="number">21</span>])</div></pre></td></tr></table></figure>
<p>To save model:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">gbm.save_model(<span class="string">'model.txt'</span>)</div></pre></td></tr></table></figure>
<p>To continue the training from saved model:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">gbm = lgb.train(params, lgb_train, num_boost_round=<span class="number">10</span>,</div><div class="line">                init_model=<span class="string">'model.txt'</span>, valid_sets=lgb_eval)</div></pre></td></tr></table></figure>
<p>Or continue the training with the model object and changed settings</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">gbm = lgb.train(params, lgb_train, num_boost_round=<span class="number">10</span>,</div><div class="line">                learning_rates=<span class="keyword">lambda</span> iter: <span class="number">0.05</span> * (<span class="number">0.99</span> ** iter),</div><div class="line">                valid_sets=lgb_eval, init_model=gbm)</div></pre></td></tr></table></figure>
<p>To predict:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)</div></pre></td></tr></table></figure>
<p>All example code above can be found <a href="https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide" target="_blank" rel="external">here</a></p>
<h1 id="Future"><a href="#Future" class="headerlink" title="Future"></a>Future</h1><p>LightGBM provides C++ and Python API as of now. The DMTK team has plans to support the following platforms in the future:</p>
<ul>
<li>R and Julia</li>
<li>Hadoop and Spark</li>
<li>GPU speedup</li>
</ul>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>Meng, Q., Ke, G., Wang, T., Chen, W., Ye, Q., Ma, Z. M., &amp; Liu, T. (2016). A Communication-Efficient Parallel Algorithm for Decision Tree. In Advances in Neural Information Processing Systems (pp. 1271-1279).</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Microsoft-LightGBM&quot;&gt;&lt;a href=&quot;#Microsoft-LightGBM&quot; class=&quot;headerlink&quot; title=&quot;Microsoft LightGBM&quot;&gt;&lt;/a&gt;Microsoft LightGBM&lt;/h1&gt;&lt;p&gt;People
    
    </summary>
    
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
      <category term="tool" scheme="http://yoursite.com/tags/tool/"/>
    
  </entry>
  
  <entry>
    <title>Alpha Beta Pruning</title>
    <link href="http://yoursite.com/2016/09/alpha-beta-pruning/"/>
    <id>http://yoursite.com/2016/09/alpha-beta-pruning/</id>
    <published>2016-09-12T18:33:49.000Z</published>
    <updated>2017-01-07T16:03:51.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Minimax"><a href="#Minimax" class="headerlink" title="Minimax"></a>Minimax</h1><p>Minimax algorithm with <a href="https://en.wikipedia.org/wiki/Alpha–beta_pruning" target="_blank" rel="external">Alpha-beta pruning</a> is a very classic algorithm in AI used for improving the efficiency of game tree searching. It’s not very different from typical branch &amp; bound types of algorithms in optimization fields. <a href="http://inst.eecs.berkeley.edu/~cs61b/fa14/ta-materials/apps/ab_tree_practice/index.html" target="_blank" rel="external">This link</a> provides a very good visualization.</p>
<p>In practice there are many different variations of minimax, depending on the characteristics of the game. For example, there are games with perfect imformation (go) vs. imperfect imformation (Texas Hold ‘em), or deterministic (chess) vs. stochastic (backgammon). In any case the algorithm should work in similar fashion, with only variations such as game states may be defined differently or the utility function for each move might vary (e.g., score vs. expected score).</p>
<p>To abstract from any specific game, let’s assume we have defined a generic “Game” class, with APIs such as</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Game</span>:</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">get_legal_moves</span><span class="params">(self)</span>:</span></div><div class="line">		<span class="string">'''get all legal moves for current player'''</span></div><div class="line">		<span class="keyword">return</span> legal_moves</div><div class="line">		</div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">forecast_move</span><span class="params">(self, move)</span>:</span></div><div class="line">        <span class="string">'''play one move and return the next game state'''</span></div><div class="line">        <span class="keyword">return</span> Game_next_round</div></pre></td></tr></table></figure>
<p>Let’s also define a utility function such as</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">utility</span><span class="params">(game, maximizing_player=True)</span>:</span></div><div class="line">	<span class="string">'''utility function</span></div><div class="line">	:param game: a Game object</div><div class="line">	:param maximizing_player: is minimizing or maximizing player playing the current move?</div><div class="line">	'''</div><div class="line">    <span class="keyword">if</span> game.is_winner(self):</div><div class="line">        <span class="keyword">return</span> float(<span class="string">"inf"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> game.is_opponent_winner(self):</div><div class="line">        <span class="keyword">return</span> float(<span class="string">"-inf"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> some_score_depending_on_the_game</div></pre></td></tr></table></figure>
<p>Now we can code the minimax algorithm as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">minimax</span><span class="params">(game, utility, depth=float<span class="params">(<span class="string">"inf"</span>)</span>, maximizing_player=True)</span>:</span></div><div class="line">    <span class="string">'''minimax algorithm </span></div><div class="line">    :param game: a Game object</div><div class="line">    :param utility: a function that returns a score given current game state  </div><div class="line">    :param depth: current search depth</div><div class="line">    :param maximizing_player: is current depth at minimizing layer or maximizing layer?</div><div class="line">    :return: best move and best score</div><div class="line">    '''</div><div class="line"></div><div class="line">    <span class="keyword">if</span> depth == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> <span class="keyword">None</span>, utility(game, maximizing_player)</div><div class="line"></div><div class="line">    legal_moves = game.get_legal_moves()</div><div class="line">    </div><div class="line">    best_move = <span class="keyword">None</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> maximizing_player:</div><div class="line">        best_val = float(<span class="string">"-inf"</span>)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        best_val = float(<span class="string">"inf"</span>)</div><div class="line">    </div><div class="line">    <span class="keyword">for</span> move <span class="keyword">in</span> legal_moves:</div><div class="line">        game_next = game.forecast_move(move)</div><div class="line">        m, v = minimax(game_next, utility, depth - <span class="number">1</span>, <span class="keyword">not</span> maximizing_player)</div><div class="line">        <span class="keyword">if</span> (maximizing_player <span class="keyword">and</span> v &gt; best_val) <span class="keyword">or</span> ((<span class="keyword">not</span> maximizing_player) <span class="keyword">and</span> v &lt; best_val):</div><div class="line">            best_move = move</div><div class="line">            best_val = v</div><div class="line"></div><div class="line">    <span class="keyword">return</span> best_move, best_val</div></pre></td></tr></table></figure>
<h1 id="Alpha-beta-Pruning"><a href="#Alpha-beta-Pruning" class="headerlink" title="Alpha-beta Pruning"></a>Alpha-beta Pruning</h1><p>The naive implementation of minimax is slow especially with large depth, b/c it tries to search in every branch and every node in the game tree.  To improve the efficiency we want to play some branch &amp; bound trick, which is exactly alpha beta pruning. </p>
<p>Take an example, assume we are currently on a minimizing layer, and previous node (named A) returns a score of 10. Now we go to the next node (named B) and search all its children one level down, which is in turn a maximizing layer. Assume the first child (named B_c1) returns a score of 11, then we know immediately that B has score at least 11, which is greater than 10 (score of A). Thus B would have no contribution on it’s minimizing layer. Therefore we can skip all nodes after B_c1. In this scenario we skip if the current value &gt;= 10, and that threshold is named “alpha”.  A similar argument can be applied to maximizing layer as well, where we can skip if current value &lt;= a threshold, which is called “beta”.</p>
<p>Here is the code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">alphabeta</span><span class="params">(self, game, utility, depth=float<span class="params">(<span class="string">"inf"</span>)</span>, alpha=float<span class="params">(<span class="string">"-inf"</span>)</span>,</span></span></div><div class="line">              beta=float<span class="params">(<span class="string">"inf"</span>)</span>, maximizing_player=True):</div><div class="line">    <span class="string">'''minimax with alpha-beta pruning'''</span></div><div class="line">    </div><div class="line">    <span class="keyword">if</span> depth == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> <span class="keyword">None</span>, utility(game, maximizing_player)</div><div class="line">    </div><div class="line">    legal_moves = game.get_legal_moves()</div><div class="line">    </div><div class="line">    best_move = <span class="keyword">None</span></div><div class="line">    </div><div class="line">    <span class="keyword">if</span> maximizing_player:</div><div class="line">        best_val = float(<span class="string">"-inf"</span>)</div><div class="line">        <span class="keyword">for</span> move <span class="keyword">in</span> legal_moves:</div><div class="line">            game_next = game.forecast_move(move)</div><div class="line">            m, v = alphabeta(game_next, utility, depth - <span class="number">1</span>, alpha, beta, <span class="keyword">False</span>)</div><div class="line">            </div><div class="line">            <span class="keyword">if</span> v &gt; best_val:</div><div class="line">                best_val = v</div><div class="line">                alpha = v</div><div class="line">                best_move = move</div><div class="line">        </div><div class="line">            <span class="keyword">if</span> alpha &gt;= beta:</div><div class="line">                <span class="keyword">break</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        best_val = float(<span class="string">"inf"</span>)</div><div class="line">        <span class="keyword">for</span> move <span class="keyword">in</span> legal_moves:</div><div class="line">            game_next = game.forecast_move(move)</div><div class="line">            m, v = alphabeta(game_next, utility, depth - <span class="number">1</span>, alpha, beta, <span class="keyword">True</span>)</div><div class="line"></div><div class="line">            <span class="keyword">if</span> v &lt; best_val:</div><div class="line">                best_val = v</div><div class="line">                beta = v</div><div class="line">                best_move = move  </div><div class="line">            </div><div class="line">            <span class="keyword">if</span> beta &lt;= alpha:</div><div class="line">                <span class="keyword">break</span>                </div><div class="line">    <span class="keyword">return</span> best_move, best_val</div></pre></td></tr></table></figure>
<h1 id="Further-Improvements"><a href="#Further-Improvements" class="headerlink" title="Further Improvements"></a>Further Improvements</h1><p>The above code only provides one particular implementation of alpha-beta pruning. In practice there are many variations. Here I would mention two: </p>
<ul>
<li><p><strong>Pre-order the nodes</strong></p>
<p>The performance of alpha-beta pruning depends a lot on how do u rearrange your nodes. Assuming we search the game tree from left to right, idealy you want to put large valued nodes to the left on maximizing layer, and small valued nodes to the left on minimizing layer. </p>
</li>
<li><p><strong>Iterative deepening</strong></p>
<p>Due to the exponential nature of the game tree, most of the search time is spent on the bottom level. Given a fixed amount of time for each round, we can iteratively increase the depth of the search algorithm until we hit the time limit. What’s nice about this are two folds: 1. You always get an answer quickly, and can use the rest of the time looking for better solutions; 2. In later stages of the game, the branching factor (possible moves) will likely to be significantly less than the beginning of the game, so given the same amount of time, we can do deeper search towards the end of the game, which is arguably the more important stage of the game.</p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Minimax&quot;&gt;&lt;a href=&quot;#Minimax&quot; class=&quot;headerlink&quot; title=&quot;Minimax&quot;&gt;&lt;/a&gt;Minimax&lt;/h1&gt;&lt;p&gt;Minimax algorithm with &lt;a href=&quot;https://en.wikiped
    
    </summary>
    
    
      <category term="AI" scheme="http://yoursite.com/tags/AI/"/>
    
      <category term="algorithm" scheme="http://yoursite.com/tags/algorithm/"/>
    
  </entry>
  
</feed>
